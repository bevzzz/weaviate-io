---
title: Compression
sidebar_position: 30
image: og/docs/tutorials.jpg
# tags: ['basics']
---

Use compression to lower system requirements and save on infrastructure costs.

## Overview

import VectorsBig from '/_includes/starter-guides/vectors-are-big.mdx';

<VectorsBig/>

Weaviate creates indexes to search the vector space for your collection. By default, the vector index is an [Hierarchical Navigable Small World (HNSW)](/developers/weaviate/concepts/vector-index#hierarchical-navigable-small-world-hnsw-index) index which includes the vector as well as a graph structure. HNSW indexes allow fast vector searches while maintaining excellent recall, but they can be expensive to use as they are stored in memory.

In many cases, you can use compression or a different index type to change the way Weaviate stores and searches your data, and still maintain high levels of recall. Updating the default settings can result in significant cost savings and performance improvements.

This page discusses compression algorithms. For more on indexes, see [Vector indexing](/developers/weaviate/concepts/vector-index).

## Compression algorithms

These compression algorithms are available:

import CompressionAlgorithms from '/_includes/starter-guides/compression-types.mdx';

<CompressionAlgorithms />

When you compress vectors, the quality of your search results depends heavily on the characteristics of the uncompressed vectors. The embedding model produces these vectors. Therefore the embedding model is key to retrieval performance of the compressed vectors. Before moving to production, experiment with different compression settings and embedding models and review the model documentation to find the combination that works best with your data set.

## Compression considerations

Before choosing a compression algorithm, consider the [underlying vector index type](#underlying-vector-index). The index type determines which compression algorithms you can use. Some compression algorithms aren't available with some index types.

The vectorizer that you use to create your object vectors may also limit your compression choices. For example, some embedding models are tuned specifically for BQ compression.

Performance and cost are also important considerations. See [Cost, recall, and speed](#cost-recall-and-speed) for details.

### Underlying vector index

This table shows which compression algorithm is available for each index type.

| Compression type | HNSW index | Flat index | Dynamic index |
| :- | :- | :- | :- |
| PQ | Yes | No | Yes |
| SQ | Yes | No | Yes |
| BQ | Yes | Yes | Yes |

The [dynamic index](/developers/weaviate/config-refs/schema/vector-index#dynamic-indexes) is new in v1.25. This type of index is a [flat index](/developers/weaviate/config-refs/schema/vector-index#flat-indexes) until a collection reaches a threshold size. When the collection grows larger than the threshold size, the default is 10,000 objects, the collection is automatically reindexed and converted to an HNSW index.

### Cost, recall and speed

Performance includes speed and recall. In real world systems, these factors have to be balanced against cost. As you develop familiarity with your application, you can tune Weaviate to match your project and budget requirements.

#### Cost

import CostSavings from '/_includes/starter-guides/cost-savings.mdx';

<CostSavings/>

An HNSW index comprises a connection graph as well as the vectors. Quantization methods reduce the size of the vectors, but does not affect the size of the graph. As a result the overall reduction in memory usage is less than the reduction in vector size, but still significant.

#### Recall

import RecallDetails from '/_includes/starter-guides/recall-details.mdx';

<RecallDetails/>

#### Query speed

import QuerySpeed from '/_includes/starter-guides/query-speed.mdx';

<QuerySpeed/>

#### Import speed

Importing and compressing vectors takes slightly longer than importing uncompressed vectors, but this is a one time cost. In contrast, loading a compressed index into memory is faster since there is less data to load. This means restarts are faster.

Starting in v1.22, Weaviate has an optional, [asynchronous indexing](/developers/weaviate/config-refs/schema/vector-index#asynchronous-indexing) feature which effectively speeds up the import process. Consider enabling asynchronous indexing to improve imports.

### Activate compression

PQ and SQ both require training data. PQ has to define centroids for each segment. SQ has to determine the minimum and maximum values for the bucket boundaries. When you have imported a large enough training set, the algorithm compresses your data.

SQ has to be enabled when you create the collection.

If you have async indexing and [AutoPQ enabled](/developers/weaviate/configuration/compression/pq-compression#configure-autopq), PQ compression can be started anytime. If not, you should only enable PQ after you have imported enough objects to [train the algorithm](/developers/weaviate/configuration/compression/pq-compression#manually-configure-pq).

BQ doesn't require a training step, however it can only be enabled when you create your collection. BQ cannot be enabled after you start to add data to the collection.

## Recommendations

Most applications benefit from compression.

- The cost savings are significant. In [Weaviate Cloud](https://weaviate.io/pricing), for example, compressed collections can be more than 80% cheaper than uncompressed collections.
- If you have a small collection that uses a flat index, consider a BQ index. The BQ index is 32 times smaller and much, much faster than the uncompressed equivalent.
- If you have specialized needs and a very large data set, consider PQ compression. PQ compression is very configurable, but it requires more expertise to tune well than SQ or BQ.
- Most users with medium to large data sets should consider SQ compression. SQ compressed vectors are one quarter the size of uncompressed vectors. Searches with SQ are faster than searches with uncompressed vectors. Recall is similar to uncompressed vectors.

For collections that are small, but that are expected to grow, consider a dynamic index. In addition to setting the dynamic index type, configure the collection to use BQ compression while the index is flat and SQ compression when the collection grows large enough to move from a flat index to an HNSW index.

## Related pages

For more information, see these documentation pages and blog posts.

### Documentation pages

To enable compression, follow the steps on these pages:

- [Product quantization (PQ)](../../configuration/compression/pq-compression.md)
- [Scalar quantization (SQ)](../../configuration/compression/sq-compression.md)
- [Binary quantization (BQ)](../../configuration/compression/bq-compression.md)

For more documentation details, see:

- [Compression discussion](/developers/weaviate/concepts/vector-quantization)

### Blog posts

For in-depth discussions, see:

- [PQ and memory reduction](/blog/pq-rescoring)
- [BQ and memory reduction](/blog/binary-quantization)
- [PQ and HNSW explained](/blog/ann-algorithms-hnsw-pq)

### Pricing calculator

To review Weaviate Cloud pricing for compressed and uncompressed vectors, see:

[Weaviate cloud pricing calculator](https://weaviate.io/pricing)

## Questions and feedback

import DocsFeedback from '/_includes/docs-feedback.mdx';

<DocsFeedback/>
